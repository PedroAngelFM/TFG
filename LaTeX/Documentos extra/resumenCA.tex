\section{Análisis de Clusters}

\noindent Según Jain y Dubes  el análisis de \emph{cluster} es un conjunto de técnicas que toman un conjunto de datos resultantes de recoger $N$ observaciones sobre $p$ medidas diferentes y buscan agruparlas utilizando diferentes criterios. También se puede utilizar para crear agrupaciones de variables pero no se desarrollará en demasiada profundidad. 

\noindent Para empezar, debemos definir que es un \emph{cluster}. Como en nuestro caso no buscamos agrupar variables, sino observaciones o mediciones utilizaremos la definición dada en \cite{Everitt 2011}.
\begin{defi}
Diremos que un \emph{cluster} o conglomerado es un subconjunto de las observaciones que son similares entre sí. 
\end{defi}

\noindent Es fácil observar que los clusters definen la siguiente relación de equivalencia $\mathcal{R}$ en la que dos observaciones, $\mathbf{x}_i,\mathbf{x}_{i'}, i,i'=1, \ldots, N$ están relacionadas si pertenecen al mismo clúster \cite{Cuadras 2014}. Por tanto, cada \emph{cluster} genera una clase de equivalencia $[c_c], c=1\ldots C$ donde $C$ es el número de clusters

\noindent El conjunto de \emph{clusters} generan un \emph{clustering} o partición , es decir:
\begin{defi}
Se llama \textit{clustering} a la partición que provoca la relación $\mathcal{R}$ del espacio de observaciones. 
\end{defi}

\noindent Para llegar a dichas particiones podemos usar distintos tipos de algoritmos según el número de particiones distintas que se generen a lo largo del proceso \cite{Jain 1988}:
\begin{itemize}
\item Particional Son aquellos procesos de \emph{clustering} en los que de manera previa se conocen el número de \emph{clusters} y por tanto, se genera una partición que se va modificando.
\item Jerárquico, si el proceso genera una secuencia anidada de particiones, es decir, que dependiendo de cómo se desarrolle puede ser de los siguientes tipos:
\begin{itemize}
\item Aglomerativo Cuando se inicia con una partición que tiene $N$ \emph{clusters} con una observación en cada uno. Este tipo de algoritmos va tomando los \emph{clusters} y junta aquellos según un criterio establecido hasta llegar a un criterio de parada. 
\item Divisivo Cuando empieza con un único \emph{cluster} que contiene a las $N$ observaciones. En cada paso se va dividiendo los cluster siguiendo algún criterio hasta llegar al criterio de parada. 
\end{itemize}
\end{itemize}

\noindent En resumen, el análisis de cluster es un conjunto de técnicas que permiten la simplificación estructural de las observaciones recogidas de un vector aleatorio mediante la agrupación de las mismas en conjuntos llamados clusters \cite{Everitt 2011}. 

\noindent El análisis de clusters ha sido aplicado en infinidad de áreas como el marketing con el objetivo de segmentar los anuncios \cite{Okazaki 2006}, la psicología para detectar si se da un sólo trastorno en una población \cite{Everitt 2002} o en el caso de la medicina para intentar estudiar la supervivencia de pacientes con carcinoma renal \cite{Witten 2010}. Estos son ejemplos de unas pocas aplicaciones, pero también nos pueden ayudar en la predicción del riesgo crediticio, segmentación electoral etc... 

\subsection{Algoritmos jerárquicos}

\noindent Los algoritmos jerárquicos calculan en cada paso la similaridad o disimilaridad entre \emph{clusters} para generar nuevas particiones del espacio uniendo o separando los distintos \emph{clusters}.

\noindent Un algoritmo jerárquico genera una secuencia de particiones anidada que está definida de la siguiente manera \cite{Scitovski 2021} :
\begin{defi}
Una partición del espacio $\Pi^{(r)}$ está anidada en otra partición $\Pi^{(k)}$ y se denota $\Pi^{(r)} \sqsubset \Pi^{(k)}$ si cumple lo siguiente:
\begin{itemize}
\item El número de clusters de $\Pi^{(k)}$ es menor que el de $\Pi^{(r)}$. 
\item Cada cluster de la partición $\Pi^{(r)}$ es un subconjunto de algún cluster de $\Pi^{(k)}$. 
\end{itemize}
En el caso de un algoritmo aglomerativo tendremos que $k>r$, es decir en el paso $k$-ésimo el número de \emph{clusters}.

\end{defi}

\noindent La pregunta que hay que hacer antes de aplicar este tipo de algoritmos, es cómo calcular las distancias o similaridad entre dos observacioens . Hay que distinguir dos casos, el cálculo inicial de las distancias entre observaciones del espacio y la distancia entre clusters. Dependiendo de como se elijan sobre todo las últimas se tendrá un algoritmo de clustering u otro \cite{Peña 2002}. 

\noindent Para empezar, se define el concepto de similaridad. Este concepto nos ayuda a entender cuando dos observaciones son lo suficientemente iguales para agruparlas juntas \cite{Mardia 1979, Peña 2002}. 

\begin{defi}
Llamaremos similaridad entre dos observaciones  $i,h$ según la variable $j$ a una función $s_{jih}$ la cual cumpla que :
\begin{itemize}
\item La similaridad de una muestra consigo misma es igual a la unidad $s_{jii}=1 \\ \forall j=1,\ldots,p \quad i=1,\ldots, N$
\item $0\leq s_{jih} \leq 1\quad \forall j=1,\ldots,p \quad \forall i,h=1,\ldots N  $
\item Simetría: $s_{jih}=s_{jhi}$
\end{itemize}
\end{defi}