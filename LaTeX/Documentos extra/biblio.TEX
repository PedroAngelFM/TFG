
\begin{thebibliography}{99}
    \rhead[]{Bibliografía}
	
	\addcontentsline{toc}{chapter}{Bibliografía}

\bibitem{Abdi 2010} \textbf{Abdi, H., and Williams, L. J. (2010).} Principal component analysis. Wiley \emph{Interdisciplinary Reviews: Computational Statistics}  2(4), 433–459. 

\bibitem{Abdi 2007}\textbf{Abdi, H. (2007).} The method of least squares. \emph{Encyclopedia of measurement and statistics}, 1, 530-532.

\bibitem{Biau 2016}\textbf{Biau, G., and Scornet, E. (2016)}. \textit{A random forest guided tour}. Test, 25, 197-227.

\bibitem{Breiman 2004}\textbf{Breiman, L. (2004).} Consistency for a simple model of random forests. \emph{University of California at Berkeley. Technical Report,} 670.

\bibitem{Brown 2004} \textbf{Myles, A. J., Feudale, R. N., Liu, Y., Woody, N. A., and Brown, S. D. (2004).} An introduction to decision tree modeling. \emph{Journal of Chemometrics: A Journal of the Chemometrics Society}, 18(6), 275-285.

\bibitem{Chatfield 1989} \textbf{Chatfield,C and Collins A.J (1989)}. {\em Introduction to multivariate analysis}, Chapman and Hall.

\bibitem{Diaz 2006}\textbf{Díaz-Uriarte, R., and Alvarez de Andrés, S. (2006).} Gene selection and classification of microarray data using random forest. \emph{BMC bioinformatics,} 7, 1-13.

\bibitem{Cuadras 2014} \textbf{Cuadras, C.M. (2014)}, \textit{Nuevos métodos de Análisis Multivariante}, CMC Editions, Barcelona. 

\bibitem{Hastie 2001} \textbf{Hastie, T., Tibshirani, R. and Friedman J. (2001)}, \textit{The Elements of Statistical Learning, Data Mining, Inference and Prediction} Springer 

\bibitem{Hair 1995}\textbf{Hair, J. F., Black, W. C., Tatham, R. L., and Anderson, R. E. (1995).}
\textit{ Multivariate data analysis with readings.} Prentice-Hall International, Englewood Cliffs, New Yersey. 


\bibitem{Jollife 1986} \textbf{Jollife I.T.(1986)}. \emph{Principal Component Analysis}, Springer-Verlag.

\bibitem{Koppen 2000} \textbf{Köppen, M. (2000)} The curse of dimensionality. \textit{5th online world conference on soft computing in industrial applications (WSC5)}  (Vol. 1, pp. 4-8).


\bibitem{Jain 1988} \textbf{Jain, A.K., Richard, C.D., (1988)} \textit{Algorithms for clustering data.} Prentice-Hall, Inc. 

\bibitem{Sckit-Learn} \textit{Scikit Learn Documentation, Clustering Methods. } \url{https://scikit-learn.org/stable/modules/clustering.html#clustering}


\bibitem{Neural Designer} Neural Designer Blog \url{https://www.neuraldesigner.com/}
          
\bibitem{Roberto 2008} \textbf{Lopez, R., Balsa-Canto, E. and Oñate, E. (2008)}  Neural networks for variational problems in engineering \emph{Int. J. Numer. Meth. Engng.}, 75\\ \url{https://doi.org/10.1002/nme.2304} 1341-1360. 


\bibitem{Lebart 1984}\textbf{Lebart, L., Morineau, A.,  Warwick, K. M. (1984)}.\textit{Multivariate Descriptive Analysis: Correspondence analysis and related techniques for large matrices}. Wiley.

\bibitem{Morrison 1976}\textbf{Morrison. D.(1976).}\textit{ Multivariate statistical methods (2nd ed)}. McGraw-Hill Kogakusha.

\bibitem{Batista, 1989}
\textbf{Batista Foguet, J.M. y Martínez Arias, R. (1989)}\textit{Análisis Multivariante: Análisis en Componentes Principales. } Editorial Hispano Europea.

\bibitem{Divakaran 2022}\textbf{Divakaran, S. (2022). }Data Science: Principles and Concepts in Modeling Decision Trees.\emph{ Data Science in Agriculture and Natural Resource Management}, 55-74.

\bibitem{James 2013}
\textbf{James G, Witten D, Hastie T, Tibshirani R.} \emph{An Introduction to Statistical Learning: With Applications in R.} New York, NY: Springer; 2021. 
  


\bibitem{Rosario 1999} 
\textbf{Martínez Arias R.} \emph{El análisis multivariante en la investigación científica.} Madrid: La Muralla; 1999. 
  


\bibitem{Peña 2002} 
\textbf{Peña D.} \emph{Análisis de datos multivariantes.} Madrid: McGraw-Hill; 2002.

\bibitem{Galindo 2015}\textbf{Andrade-Sánchez, A. I., Galindo-Villardón, M. P., y Cuevas Romo, J. (2015).} Análisis multivariante del perfil psicológico de los deportistas universitarios: Aplicación del CPRD en México. \emph{Educación Física y Ciencia}, 17(2), 00-00.

\bibitem{Diez 2002}\textbf{Hernandis, S. P., Diez, J. P., y Rouma, A. C. (2002).} El consumo de inhalables y cannabis en la preadolescencia: Análisis multivariado de factores predisponentes. \emph{Anales de Psicología/Annals of Psychology}, 18(1), 77-93.

\bibitem{Echeverri 2015} \textbf{Machado-Duque, M. E., Echeverri Chabur, J. E., y Machado-Alba, J. E. (2015).} Somnolencia diurna excesiva, mala calidad del sueño y bajo rendimiento académico en estudiantes de Medicina. \emph{Revista colombiana de Psiquiatría,} 44(3), 137-142.


%\bibitem{González 2015} \textbf{González García, N., y Taborda Londoño, A.} \emph{Análisis de componentes principales Sparse: formulación, algoritmos e implicaciones en el análisis de datos.} Salamanca,  2015

\bibitem{Hornik 1989} \textbf{Hornik, K., Stinchcombe, M., and White, H. } Multilayer feedforward networks are universal approximators. \emph{Neural networks}, 2(5), 359-366, 1989.
\url{https://doi.org/10.1016/0893-6080(89)90020-8}

%\bibitem{Iris Fisher} \textbf{Fisher,R. A.. (1988).} Iris. \emph{UCI Machine Learning Repository. }\url{https://doi.org/10.24432/C56C76}. 
\bibitem{Alubias} \textbf{Dry Bean Dataset. (2020)}.\emph{ UCI Machine Learning Repository. } \url{https://doi.org/10.24432/C50S4B.}

\bibitem{Pages 2005}\textbf{Pagès, J. (2005).} Collection and analysis of perceived product inter-distances using multiple factor analysis: Application to the study of 10 white wines from the Loire Valley. \emph{Food quality and preference}, 16(7), 642-649.  \url{https://doi.org/10.1016/j.foodqual.2005.01.006
}

\bibitem{Okazaki 2006}\textbf{Okazaki, S. (2006).} What do we know about mobile Internet adopters? A cluster analysis. \emph{Information \& Management,} 43(2), 127-141. 

\bibitem{Mamidi 2021}\textbf{Mamidi, R. R. (2021)}. Application of Neural Networks for Prediction of Double Fed Induction Generator’s Equivalent Circuit Parameters used in Wind Generators. \emph{IRJCS:: International Research Journal of Computer Science}, Volume VIII, 23-31.

\bibitem{Nerini 2007}\textbf{Nerini, D., \& Ghattas, B. (2007).} Classifying densities using functional regression trees: Applications in oceanology. \emph{Computational Statistics \& Data Analysis} 51(10), 4984-4993.

\bibitem{Ensum 2005}\textbf{Ensum, J., Pollard, R., \& Taylor, S. (2005).} Applications of logistic regression to shots at goal at association football. \emph{In Science and football V: the proceedings of the Fifth World Congress on Science and Football} (pp. 214-221).

\bibitem{Greene 2008}\textbf{Greene,  W.H.} (2008). \emph{Econometric analysis (6th ed.)} Pearson Prentice Hall
\bibitem{Johnson 2007}\textbf{Johnson, R. A., \& Wichern, D. W. (2007)}. \emph{Applied multivariate statistical analysis.(6th edition)} Pearson Prentice Hall.

\bibitem{Everitt 2011}\textbf{Everitt, B., and Hothorn, T. (2011)}. \emph{An introduction to applied multivariate analysis with R}. Springer Science \& Business Media.

\bibitem{Ringnér 2008}\textbf{Ringnér, M. (2008).}What is principal component analysis?.\emph{Nature biotechnology, 26(3), 303-304.}

\bibitem{Asari 2004} \textbf{Gottumukkal, R., \& Asari, V. K. (2004).} An improved face recognition technique based on modular PCA approach.\emph{ Pattern Recognition Letters,} 25(4), 429-436.

\bibitem{Eckart 1936}\textbf{Eckart, C., \& Young, G. (1936).} The approximation of one matrix by another of lower rank. \emph{Psychometrika}, 1(3), 211-218.

\bibitem{Johnson 1963} \textbf{Johnson, R. M. (1963).} On a theorem stated by Eckart and Young. \emph{Psychometrika}, 28(3), 259-263.

\bibitem{Golub 1987}\textbf{Golub, G. H., Hoffman, A., \& Stewart, G. W. (1987)}. A generalization of the Eckart-Young-Mirsky matrix approximation theorem. \emph{Linear Algebra and its applications}, 88, 317-327.

\bibitem{Mahesh 2020}\textbf{Mahesh, B. (2020).} Machine learning algorithms-a review. \emph{International Journal of Science and Research (IJSR)}, 9, 381-386.

\bibitem{Pearson 1901} \textbf{Pearson, K. (1901)}. LIII. On lines and planes of closest fit to systems of points in space. \emph{The London, Edinburgh, and Dublin philosophical magazine and journal of science,} 2(11), 559-572.

\bibitem{Hotelling 1933}\textbf{Hotelling H. (1933)} Analysis of a complex of statistical variables
into principal components. \emph{J Educ Psychol }
25:417–441.

\bibitem{Vincent 1953}\textbf{Vincent, D. F. (1953).} The origin and development of factor analysis. \emph{Journal of the Royal Statistical Society: Series C (Applied Statistics),} 2(2), 107-117.

\bibitem{Galton  1889} \textbf{Galton, F. (1889).} Co-relations and their measurement, chiefly from anthropometric data.\emph{ Proceedings of the Royal Society of London,} 45(273-279), 135-145.

\bibitem{Spearman 1904}\textbf{Spearman, C. (1904).} “General Intelligence,” Objectively Determined and Measured. \emph{The American Journal of Psychology,} 15(2), 201–292. \url{https://doi.org/10.2307/1412107}

\bibitem{Mardia 1979}\textbf{Mardia, K.V., Kent, J.T. and Bibby J.M.; (1979)}. \emph{Multivariate analysis}. Academic Press.

\bibitem{Song 2015}\textbf{Song, Y. Y., and Ying, L. U. (2015).} Decision tree methods: applications for classification and prediction. \emph{Shanghai archives of psychiatry,} 27(2), 130.

\bibitem{Lawless 2010} \textbf{Lawless, J. F., \& Yuan, Y. (2010).} Estimation of prediction error for survival models. \emph{Statistics in medicine,} 29(2), 262-274.

\bibitem{Loh 2011}\textbf{Loh, W. Y. (2011).} Classification and regression trees.\emph{ Wiley interdisciplinary reviews: data mining and knowledge discovery}, 1(1), 14-23.

\bibitem{Breiman 1984}\textbf{Breiman, L. (1984).} \emph{Classification and regression trees. }Chapman \& Hall.

\bibitem{Hesterberg 2011}\textbf{Hesterberg, T. (2011).} Bootstrap. \emph{Wiley Interdisciplinary Reviews: Computational Statistics,} 3(6), 497-526.
\bibitem{Breiman 1996}\textbf{Breiman, L. (1996).} Bagging predictors. \emph{Machine learning}, 24, 123-140.
\bibitem{Breiman 2001}\textbf{Breiman, L. (2001).} Random forests. \emph{Machine learning}, 45, 5-32.
\bibitem{Koklu 2020}\textbf{Koklu, M., \& Ozkan, I. A. (2020).} Multiclass classification of dry beans using computer vision and machine learning techniques. \emph{Computers and Electronics in Agriculture,} 174, 105507.
\bibitem{Livingstone 1997}\textbf{Livingstone, D. J., Manallack, D. T., \& Tetko, I. V. (1997).} Data modelling with neural networks: Advantages and limitations. \emph{Journal of computer-aided molecular design}, 11, 135-142.
\bibitem{Hochreiter 1997}\textbf{Hochreiter, S., \& Schmidhuber, J. (1997).} Long short-term memory.\emph{ Neural computation}, 9(8), 1735-1780.
\bibitem{Quinlan 2014}\textbf{Quinlan, J. R. (2014)}. \emph{C4. 5: programs for machine learning.} Elsevier.

\bibitem{Loh 2014}\textbf{Loh, W. Y. (2014).} Fifty years of classification and regression trees. \emph{International Statistical Review}, 82(3), 329-348.

\bibitem{Kass 1980}\textbf{Kass, G. V. (1980)}. An exploratory technique for investigating large quantities of categorical data. \emph{Journal of the Royal Statistical Society: Series C (Applied Statistics)}, 29(2), 119-127.

\bibitem{Grossi 2007}\textbf{Grossi, E., \& Buscema, M. (2007). }Introduction to artificial neural networks. \emph{European journal of gastroenterology \& hepatology,} 19(12), 1046-1054.

\bibitem{Villardón 2006}\textbf{Villardón, J. L. V. (2006).} \emph{Análisis discriminante: introducción.} Universidad de Salamanca: Departamento de estadistica.

\bibitem{Everitt 2011}\textbf{Landau, S., Leese, M., Stahl, D., \& Everitt, B. S. (2011}). \emph{Cluster analysis}. John Wiley \& Sons.

\bibitem{Everitt 2002} \textbf{Everitt, B., Ismail, K., David, A. S., \& Wessely, S. (2002)}. Searching for a Gulf War syndrome using cluster analysis. \emph{Psychological medicine} 32(8), 1371-1378.
\bibitem{Witten 2010}\textbf{Witten, D. M., \& Tibshirani, R. (2010).} Survival analysis with high-dimensional covariates. \emph{Statistical methods in medical research,} 19(1), 29-51.
\end{thebibliography}
 