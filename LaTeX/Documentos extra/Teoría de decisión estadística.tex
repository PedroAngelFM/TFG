\section{Teoría de decisión estadística}
Sea $X\in \mathbb{R}^p$ un vector aleatorio real e $Y \in \mathbb{R}$ una variable aleatoria real. En este contexto, $X$ e $Y$ serán las variables de entrada y la variable de salida respectivamente. Asimismo, sea $\mathbb{P}(X,Y)$ la distribución de probabilidad conjunta.   

Se busca una función $f(X)$ para predecir $Y$. Dicho predictor tiene asociada una pérdida, es decir, una forma de penalizar el error de predicción. En esta memoria, a no ser que se explicite utilizaremos el error cuadrático para las regresiones, $L(Y,f(X))=(Y-f(X))^2$ . 

\begin{defi}
Llamaremos error de predicción esperado de $f$ o $EPE(f)$ a la siguiente expresión:
\begin{equation}
EPE(f)=E(Y-f(X)^2)=\int (y-f(x))^2 \mathbb{P}(dx,dy)
\end{equation}

\noindent A priori se conocen los valores de $X$, entonces si condicionamos a dichos valores, obtenemos que $\mathbb{P}(Y,X)=\mathbb{P}(Y|X)\cdot\mathbb{P}(X)$ aplicándolo en la expresión anterior resulta que 
\begin{equation}
\begin{split}
EPE(f)&=\int (y-f(x))^2 \mathbb{P}(dx,dy)=\int\int (y-f(x))^2 \mathbb{P}(dy|dx)\mathbb{P}(dx)\\
&= \mathbb{E}_X(\mathbb{E}_{Y|X}((Y-f(X))^2|X))
\end{split}
\end{equation}

\end{defi}

\noindent Este parámetro nos ofrece un criterio para encontrar $f$, es decir, $f$ será la que minimice el $EPE(f)$ , en concreto, $f(x)=\mathbb{E}(Y|X=x)$. Añadir que este sería el caso de la regresión. 

\noindent Sea ahora $G$ una variable categórica con $K$ categorías posibles y $\mathcal{G}$ el conjunto de categorías posibles. Se define la matriz de pérdida \textbf{L} de tamaño $K\times K$ en el que el término $l_{i,j}$ es la pérdida que se da al clasificar $G_i$ como $G_j$. De manera habitual se toma la pérdida $0-1$ que se define como $l_{i,j}=1-\delta_{ij}$. 

\noindent De esta manera, la matriz de pérdida es \textit{simétrica y no negativa}. 
 
\noindent Con esta función de pérdida el error de predicción esperado pasa a ser: 
\begin{equation}
EPE(f)=\mathbb{E}(L(G,\hat{G}))=\mathbb{E}_X \sum_{k=1}^K(L(\mathcal{G}_k,\hat{G}(X))\mathbb{P}(\mathcal{G}_k|X))
\end{equation}

\noindent De esta ecuación resulta que el predictor $\hat{G}$ se explicita de la siguiente manera en el caso de la pérdida $0-1$. 

\begin{equation}
\hat{G}(X)=\mathcal{G}_k \quad \text{ si } \quad \mathbb{P}(\mathcal{G}_k|X=x)=\max_{g\in\mathcal{G}}\mathbb{P}(g|X=x)
\end{equation}


