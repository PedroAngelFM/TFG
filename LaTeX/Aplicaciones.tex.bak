\chapter{Aplicación sobre datos}

\noindent A lo largo de este capítulo se  aplicarán algunas de las técnicas desarrolladas anteriormente a ejemplos prácticos con bases de datos reales obtenidas de distintos repositorios. 

\noindent La principal herramienta usada ha sido el lenguaje de programación Python, utilizando librerías como Pandas para el manejo de las bases de datos, Scikit-Learn para la implementación de los modelos  y otras librerias de visualización como Matplotlib para la inclusión de gráficos sencillos. 

\section{Tipo de alubias}
\subsection*{Descripción del DataSet}
\noindent Este conjunto de datos,  \cite{Alubias} está formado por 12 variables predictoras que detallan \emph{Koklu, M. y Ozkan, I.A.}\cite{Koklu 2020}. En concreto las medidas son obtenidas mediante imagenes tomadas de distintas variedades de alubias ya clasificadas, en particular, las características medidas son las siguientes:
\begin{enumerate}
\item Área de la alubia medida en pixeles con sus límites incluidos.  
\item Perímetro 
\item Longitud del eje máximo
\item Longitud del eje mínimo
\item Ratio de aspecto, es decir, el cociente entre las dos medidas anteriores. 
\item Excentricidad 
\item Área convexa; número de pixeles en el menor polígono convexo. 
\item Diámetro equivalente
\item 
\item
\item Redondez
\item Compacidad
\end{enumerate}
\subsection*{Objetivos}

\noindent  \emph{Koklu, M. y Ozkan, I.A.}\cite{Koklu 2020} buscan crear distintos predictores que permitan clasificar de manera exitosa los distintos tipos de alubias ya que es complicado certificar la clase de alubia que se tiene. Es por ello que no nos centraremos en ese aspecto predictivo. Para empezar se hará una proyección mediante las variables canónicas 

\subsection*{Métodos a utilizar}
\noindent Para estudiar la estructura de los datos, se utilizará el análisis de componentes principales. Por otro lado, para comprobar la existencia de factores latentes se aplicará el análisis de factores principales. Tras aplicar ambas técnicas,
\subsection*{Desarrollo y resultados}
\subsection*{Conclusiones}

\newpage
\section{Cemento y capacidad predictora}

\subsection*{Descripción del dataset}
\noindent El dataset  \cite{Yeh 2007} es un conjunto de datos recogidos de distintos tipos de cementos con distintas densidades, en particular tenemos las siguientes variables:
\begin{table}[h]
\footnotesize
\centering
\begin{tabular}{|l|l|l|l|}
\hline
Nombre & Tipo de dato & Medida & Descripción \\
\hline
Cemento (variable 1) & continuo & kg en una mezcla m3 & Variable predictora \\
Escoria de alto horno (variable 2) & continuo & kg en una mezcla m3 & Variable predictora \\
Ceniza volante (variable 3) & continuo & kg en una mezcla $m^3$ & Variable predictora \\
Agua (variable 4) & continuo & kg en una mezcla $m^3$ & Variable predictora \\
Superplastificante (variable 5) & continuo & kg en una mezcla $m^3$ & Variable predictora \\
Agregado grueso (variable 6) & continuo & kg en una mezcla $m^3$ & Variable predictora \\
Agregado fino (variable 7) & continuo & kg en una mezcla $m^3$ & Variable predictora \\
Edad & continuo & Día (1-365) & Variable predictora \\
Resistencia a la compresión & continuo & MPa & Variable respuesta \\
\hline
\end{tabular}
\end{table}

\noindent 

\noindent En total se recogen 1030 muestras de las cuales un 70\% se utilizan para el ajuste y un 30\% para construir una estimación del error cuadratico medio de predicción. 
\subsection*{Objetivos} 

\noindent El objetivo es encontrar cual de los modelos utilizados para regresión de los detallados en el trabajo obtiene una mejor capacidad predictiva. 
\subsection*{Desarrollo}
\noindent Se ajustan 3 modelos distintos, un modelo lineal, un árbol de regresión, y una red neuronal. 
En particular, la red neuronal elegida tiene dos capas, la primera con 13 neuronas con una función de activación lineal rectificada, además de una capa de salida que tiene una única neurona. 

\noindent El árbol de decisión en cambio es el que se da por defecto en scikit learn, es decir, se divide utilizando un criterio de minimización, se utiliza el criterio de parada de un mínimo de una observación por nodo hoja. Para el resto de parámetros véase \cite{Scikit-Learn}.

\noindent Por último, el ajuste del regresor lineal es también el que viene dado por defecto, el método de los mínimos cuadrados. 

\noindent Para empezar se toman un 70\% de las muestras de manera aleatoria para realizar el ajuste de cada método. El 30\%  restante se utilizan para calcular un estimador del error cuadrático medio.

\noindent En el caso de la regresión por el modelo lineal obtenemos un error cuadrático medio de 10.30 para el conjunto de datos de ajuste. En cambio, el coeficiente de determinación ajustado $R^2$ es de un 0.61, Lo cual al estar buscando que el modelo sea lo mejor posible en el aspecto predictivo, está bien 

\subsection*{Conclusiones}
\noindent En resumen, podemos concluir que el modelo lineal no es la mejor opción para realizar predicciones. Aún así este tipo de modelos son útiles para sacar otro tipos de conclusiones como por ejemplo influencias lineales con la variable independiente. 

\noindent En cambio, los modelos de árbol de regresión y la red neuronal proporcionan mejores predicciones de manera altamente significativa con relación a la regresión mediante un modelo lineal. 