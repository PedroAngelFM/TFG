\relax 
\providecommand\babel@aux[2]{}
\@nameuse{bbl@beforestart}
\catcode `"\active 
\catcode `<\active 
\catcode `>\active 
\@nameuse{es@quoting}
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\babel@aux{spanish}{}
\@writefile{toc}{\contentsline {chapter}{\numberline {1}Métodos Supervisados}{1}{chapter.1}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {1.1}Introducción}{1}{section.1.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1.1}Mínimos cuadrados y K-vecinos más cercanos}{2}{subsection.1.1.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1.2}Decisión Estadística}{3}{subsection.1.1.2}\protected@file@percent }
\citation{Hastie 2001}
\@writefile{toc}{\contentsline {section}{\numberline {1.2}Métodos Lineales para regresión}{5}{section.1.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2.1}Ajuste de los parámetros por mínimos cuadrados}{6}{subsection.1.2.1}\protected@file@percent }
\citation{Cuadras 2014}
\newlabel{ec.F}{{1.2.22}{8}{}{equation.1.2.22}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2.2}Regresión Múltiple mediante Ortogonalización sucesiva }{8}{subsection.1.2.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2.3}Regresión sobre varias variables}{8}{subsection.1.2.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2.4}Selección de subconjuntos y métodos penalizados}{9}{subsection.1.2.4}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {1.3}Métodos de Clasificación Lineales}{10}{section.1.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.3.1}Regresión lineal de una matriz de indicadores}{10}{subsection.1.3.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.3.2}Análisis Discriminante}{10}{subsection.1.3.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.3.3}Formalización del Análisis Discriminante}{11}{subsection.1.3.3}\protected@file@percent }
\newlabel{descomposicion varianza}{{1.3.7}{11}{Formalización del Análisis Discriminante}{equation.1.3.7}{}}
\citation{Roberto 2008}
\@writefile{toc}{\contentsline {section}{\numberline {1.4}Redes Neuronales}{14}{section.1.4}\protected@file@percent }
\citation{Hastie 2001}
\@writefile{lof}{\contentsline {figure}{\numberline {1.1}{\ignorespaces Imagen extraída directamente de www.neuraldesigner.com\relax }}{15}{figure.caption.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.4.1}Proyection Pursuit Regression}{15}{subsection.1.4.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.4.2}Red Neuronal de 2 capas }{16}{subsection.1.4.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.4.3}Ajuste y uso de una Red Neuronal}{17}{subsection.1.4.3}\protected@file@percent }
\citation{Brown 2004}
\citation{Hastie 2001}
\citation{Diaz 2006}
\@writefile{toc}{\contentsline {section}{\numberline {1.5} Árboles de Decisión y Bosques Aleatorios}{18}{section.1.5}\protected@file@percent }
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{f:división}{{1.2a}{18}{Subfigure 1 1.2a}{subfigure.1.2.1}{}}
\newlabel{sub@f:división}{{(a)}{a}{Subfigure 1 1.2a\relax }{subfigure.1.2.1}{}}
\newlabel{f:diagrama arbol}{{1.2b}{18}{Subfigure 1 1.2b}{subfigure.1.2.2}{}}
\newlabel{sub@f:diagrama arbol}{{(b)}{b}{Subfigure 1 1.2b\relax }{subfigure.1.2.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.2}{\ignorespaces Representación de la división de $\mathbb  {R}^p$ y el diagrama de árbol resultante\relax }}{18}{figure.caption.4}\protected@file@percent }
\newlabel{f:MARC1}{{1.2}{18}{Representación de la división de $\mathbb {R}^p$ y el diagrama de árbol resultante\relax }{figure.caption.4}{}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {División de $\mathbb {R}^p$}}}{18}{subfigure.2.1}\protected@file@percent }
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {Diagrama resultante}}}{18}{subfigure.2.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.5.1}Árboles de Regresión}{18}{subsection.1.5.1}\protected@file@percent }
\citation{Diaz 2006}
\newlabel{Eq Cost-Complexity}{{1.5.7}{20}{Árboles de Regresión}{equation.1.5.7}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.5.2}Árboles de Clasificación}{20}{subsection.1.5.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.5.3}Bosques Aleatorios}{20}{subsection.1.5.3}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{\numberline {2}Métodos no supervisados}{21}{chapter.2}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {2.1}Introducción}{21}{section.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {2.2}Análisis de Componentes Principales}{21}{section.2.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.1}Definición y cálculo de las Componentes}{21}{subsection.2.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.2}PCA en matrices de datos}{24}{subsection.2.2.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.3}Reducción de la dimensionalidad}{25}{subsection.2.2.3}\protected@file@percent }
\citation{Jollife 1986}
\@writefile{toc}{\contentsline {section}{\numberline {2.3}Análisis Factorial}{28}{section.2.3}\protected@file@percent }
\citation{Jain 1988}
\@writefile{toc}{\contentsline {section}{\numberline {2.4}Análisis de Clusters}{29}{section.2.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4.1}Estructuración jerárquica de $\Omega $}{30}{subsection.2.4.1}\protected@file@percent }
\newlabel{Estructuración jerárquica}{{2.4.1}{30}{Estructuración jerárquica de $\Omega $}{subsection.2.4.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4.2}Algoritmos basados en jerarquías}{32}{subsection.2.4.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4.3}Elección de las diferencias }{34}{subsection.2.4.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4.4}Algoritmos no jerárquicos}{34}{subsection.2.4.4}\protected@file@percent }
\bibcite{Abdi 2010}{1}
\bibcite{Biau, 2016}{2}
\bibcite{Brown 2004}{3}
\bibcite{Chatfield 1989}{4}
\bibcite{Diaz 2006}{5}
\bibcite{Cuadras 2014}{6}
\bibcite{Hastie 2001}{7}
\bibcite{Joseph Hair 1995}{8}
\bibcite{Jollife 1986}{9}
\bibcite{Koppen 2000}{10}
\bibcite{Jain 1988}{11}
\bibcite{Sckit-Learn}{12}
\bibcite{Neural Designer}{13}
\bibcite{Roberto 2008}{14}
\bibcite{Lebart 1984}{15}
\@writefile{toc}{\contentsline {chapter}{Bibliografía}{37}{chapter*.7}\protected@file@percent }
\bibcite{Morrison 1976}{16}
\bibcite{Batista, 1989}{17}
\ttl@finishall
\newlabel{LastPage}{{}{38}{}{page.38}{}}
\xdef\lastpage@lastpage{38}
\xdef\lastpage@lastpageHy{38}
\gdef \@abspage@last{41}
